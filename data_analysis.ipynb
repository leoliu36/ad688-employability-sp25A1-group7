{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Project Working File\"\n",
        "execute:\n",
        "  kernel: ad688-venv\n",
        "bibliography: references.bib\n",
        "csl: csl/econometrica.csl\n",
        "format: \n",
        "  html:\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "    df-print: paged\n",
        "---\n",
        "\n",
        "## This file contains the code blocks for data cleaning, EDAs, skill gap analysis, NLP processing, etc. as a working file\n",
        "## Each file that contributes to the overall quarto website will contain the text and visual outputs only. \n",
        "\n",
        "\n",
        "### Code block for data_cleaning.qmd: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load lightcast_job_postings.csv \n",
        "df = pd.read_csv(\"data/lightcast_job_postings.csv\")\n",
        "df.head()\n",
        "df.columns.tolist()\n",
        "\n",
        "# Drop columns\n",
        "columns_to_drop = [\n",
        "  # tracking & other metadata\n",
        "    \"ID\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"DUPLICATES\",\n",
        "    \"SOURCE_TYPES\", \"SOURCES\", \"URL\", \"ACTIVE_URLS\", \"ACTIVE_SOURCES_INFO\", \"MODELED_EXPIRED\", \"MODELED_DURATION\", \"TITLE_RAW\",\n",
        "  # outdated NAICS and SOC codes\n",
        "    \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\",\n",
        "    \"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\",\n",
        "    \"NAICS6\", \"NAICS6_NAME\", \n",
        "    \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\",\n",
        "    \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\", \"SOC_5_NAME\",\n",
        "    \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\",\n",
        "    \"SOC_2021_5\", \"SOC_2021_5_NAME\",\n",
        "    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n",
        "    \"NAICS_2022_4\", \"NAICS_2022_4_NAME\", \"NAICS_2022_5\", \"NAICS_2022_5_NAME\"\n",
        "]\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize missing data using missingno heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "msno.bar(df)\n",
        "plt.title(\"Missing Data Bar Chart\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Identify columns that have a significant amount of missing values and sort by the percentage of missing values\n",
        "missing_values_pct = (df.isna().mean() * 100).sort_values(ascending=False).reset_index()\n",
        "missing_values_pct.columns = [\"Column\", \"Missing %\"]\n",
        "print(missing_values_pct.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill in missing values for SALARY, INDUSTRY, and other relevant columns\n",
        "# Fill categorical columns with \"Unknown\"\n",
        "fill_col_unk = [\n",
        "    \"EXPIRED\", \"MSA_INCOMING\", \"MSA_NAME_INCOMING\", \"MSA\", \"MSA_OUTGOING\", \"MSA_NAME\", \"COMPANY_RAW\", \"TITLE_CLEAN\", \"TITLE\", \"TITLE_NAME\", \"COMPANY_NAME\", \"COMPANY_IS_STAFFING\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\", \"EDUCATION_LEVELS_NAME\", \"MIN_EDULEVELS_NAME\", \"SKILLS_NAME\", \"SPECIALIZED_SKILLS_NAME\", \"CERTIFICATIONS_NAME\", \"STATE_NAME\", \"CITY_NAME\", \"COUNTY_NAME\"\n",
        "]\n",
        "# Loop through and fill missing values\n",
        "for col in fill_col_unk:\n",
        "    df[col] = df[col].fillna(\"Unknown\")\n",
        "\n",
        "# Do the same for relevant numerical columns, but fill with median\n",
        "fill_col_median = [\n",
        "    \"SALARY\", \"SALARY_FROM\", \"SALARY_TO\", \"DURATION\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\"\n",
        "]\n",
        "for col in fill_col_median:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# Drop columns with >50% missing values\n",
        "df.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove duplicate\n",
        "df=df.drop_duplicates(subset=[\"TITLE_CLEAN\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\", \"SKILLS_NAME\"], keep=\"first\")\n",
        "\n",
        "# Preview new df\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code block for eda.qmd: \n",
        "#### 5.1.1 Salary by Remote Work Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1.1 Visual - Compensation\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "values_to_exclude = ['Unknown', '[None]']\n",
        "df_filtered = df[~df['REMOTE_TYPE_NAME'].isin(values_to_exclude)]\n",
        "\n",
        "fig1 = px.box(\n",
        "    df_filtered,\n",
        "    x=\"REMOTE_TYPE_NAME\",\n",
        "    y=\"SALARY\",\n",
        "    title=\"Salary Distribution by Work Arrangement\",\n",
        "    labels={\"REMOTE_TYPE_NAME\": \"Work Arrangement\", \"SALARY\": \"Annual Salary ($)\"}\n",
        ")\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.1.2 Top Skills vs. Average Salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1.2 Visual - Skills vs. Salary\n",
        "import plotly.express as px\n",
        "import ast\n",
        "\n",
        "# This function safely converts the string of a list into an actual list\n",
        "def parse_skills(skill_list_str):\n",
        "    try:\n",
        "        return ast.literal_eval(skill_list_str)\n",
        "    except (ValueError, SyntaxError):\n",
        "        return []\n",
        "\n",
        "# Create a new column with the cleaned lists of skills\n",
        "df['SKILLS_LIST'] = df['SKILLS_NAME'].apply(parse_skills)\n",
        "\n",
        "# Create a new DataFrame where each skill gets its own row\n",
        "df_skills_exploded = df.explode('SKILLS_LIST')\n",
        "\n",
        "# --- Now, create the chart using the cleaned data ---\n",
        "top_10_skills_by_count = df_skills_exploded['SKILLS_LIST'].value_counts().nlargest(10).index\n",
        "df_top_skills = df_skills_exploded[df_skills_exploded['SKILLS_LIST'].isin(top_10_skills_by_count)]\n",
        "\n",
        "avg_salary_for_top_skills = df_top_skills.groupby('SKILLS_LIST')['SALARY'].mean().reset_index()\n",
        "\n",
        "fig2 = px.bar(\n",
        "    avg_salary_for_top_skills,\n",
        "    x='SKILLS_LIST',\n",
        "    y=\"SALARY\",\n",
        "    title=\"Average Salary for Top 10 Skills\",\n",
        "    labels={'SKILLS_LIST': \"Skill\", \"SALARY\": \"Average Annual Salary ($)\"}\n",
        ")\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.1.3 Salary Distribution by Top Industries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Query Setup\n",
        "# Convert the POSTED date from string to date format\n",
        "df[\"POSTED\"] = pd.to_datetime(df[\"POSTED\"], errors=\"coerce\")\n",
        "\n",
        "# Create a variable for the imputed median salary\n",
        "median_salary = df[\"SALARY\"].median()\n",
        "\n",
        "# Filter for job postings from 2024, specifically looking at Salary and Industry. Exclude unknowns, nulls, and zeros. Exclude imputed median salary. Exclude 'Unclassified Industry' \n",
        "df_jp_2024 = df[\n",
        "  (df[\"POSTED\"].dt.year==2024) & \n",
        "  (df[\"SALARY\"] > 0) & \n",
        "  (df[\"SALARY\"] != median_salary) &\n",
        "  (df[\"NAICS_2022_6_NAME\"]!= \"Unknown\") &\n",
        "  (df[\"NAICS_2022_6_NAME\"]!= \"Unclassified Industry\")\n",
        "]\n",
        "\n",
        "## Further filter to exclude industries that have an insignificant number of job postings\n",
        "# count the number of rows per industry  \n",
        "industry_jp_count = df_jp_2024[\"NAICS_2022_6_NAME\"].value_counts()\n",
        "\n",
        "# summarize the distribution of job counts per industry\n",
        "industry_jp_count.describe()\n",
        "\n",
        "# Set minimum threshold at 100 job postings to ensure statistical significance\n",
        "top_jp_industries = industry_jp_count[industry_jp_count > 100].index\n",
        "\n",
        "# Update df to only show top job posting industries\n",
        "df_jp_2024 = df_jp_2024[df_jp_2024[\"NAICS_2022_6_NAME\"].isin(top_jp_industries)]\n",
        "\n",
        "\n",
        "## Plot: Analyze Median Salary by Industry (Seaborn)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# group by industry name and calculate median salary, sort by descending order\n",
        "top_industry_salary_order = df_jp_2024.groupby(\"NAICS_2022_6_NAME\")[\"SALARY\"].median().sort_values(ascending=False).head(12).index\n",
        "\n",
        "# create bar chart\n",
        "plt.figure(figsize = (14,8))\n",
        "sns.barplot(\n",
        "  orient='h',\n",
        "  data=df_jp_2024,\n",
        "  x=\"SALARY\",\n",
        "  y=\"NAICS_2022_6_NAME\",\n",
        "  order=top_industry_salary_order,\n",
        "  palette=\"Set2\",\n",
        "  width=0.6,\n",
        "  estimator=np.median,\n",
        "  errorbar=None\n",
        ")\n",
        "plt.title(\"Median Salary by Industry in 2024\", fontsize=14, weight=\"bold\")\n",
        "plt.xlabel(\"Median Salary ($)\", fontsize=12)\n",
        "plt.ylabel(\"Industry\", fontsize=12)\n",
        "plt.yticks(ha=\"right\", fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show\n",
        "\n",
        "## Plot: Analyze Salary Distribution by Industry (Seaborn)\n",
        "# determine IQRs by industry:\n",
        "q25 = df_jp_2024.groupby(\"NAICS_2022_6_NAME\")[\"SALARY\"].quantile(0.25)\n",
        "q75 = df_jp_2024.groupby(\"NAICS_2022_6_NAME\")[\"SALARY\"].quantile(0.75)\n",
        "# sort by the middle 50% (Q3 - Q1) and name that as the new sorting order\n",
        "iqr = (q75 - q25).sort_values(ascending=False).head(12)\n",
        "iqr_order = iqr.index  \n",
        "\n",
        "# Create box plot\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.boxplot(\n",
        "  data=df_jp_2024,\n",
        "  y=\"NAICS_2022_6_NAME\",\n",
        "  x=\"SALARY\",\n",
        "  order=iqr_order,\n",
        "  palette=\"Set3\",\n",
        "  width=0.6\n",
        ")\n",
        "plt.title(\"Salary Distribution by Industry in 2024\", fontsize=14, weight=\"bold\")\n",
        "plt.ylabel(\"Industry\", fontsize=12)\n",
        "plt.xlabel(\"Salary ($)\", fontsize=12)\n",
        "plt.yticks(ha=\"right\", fontsize=9)\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.1.4 Salary Distribution by Top Industries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, lower, when\n",
        "\n",
        "#\n",
        "ai_keywords = [\n",
        "    \"machine learning\", \"data science\", \"artificial intelligence\",\n",
        "    \"deep learning\", \"ml engineer\", \"ai engineer\", \"data engineer\",\n",
        "    \"computer vision\", \"natural language processing\", \"nlp\", \"big data\"\n",
        "]\n",
        "\n",
        "#\n",
        "df = df.withColumn(\n",
        "    \"is_ai_job\",\n",
        "    when(\n",
        "        lower(col(\"SOC_5_NAME\")).rlike(\"|\".join(ai_keywords)) |\n",
        "        lower(col(\"LOT_SPECIALIZED_OCCUPATION_NAME\")).rlike(\"|\".join(ai_keywords)) |\n",
        "        lower(col(\"NAICS_2022_6_NAME\")).rlike(\"|\".join(ai_keywords)),\n",
        "        \"AI\"\n",
        "    ).otherwise(\"Non-AI\")\n",
        ")\n",
        "\n",
        "#\n",
        "df_filtered = df.filter(\n",
        "    (col(\"SALARY\").isNotNull()) &\n",
        "    (col(\"SALARY\") > 0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- Export All Charts -----\n",
        "import plotly.express as px\n",
        "import ast\n",
        "\n",
        "fig1.write_image(\"chart1_salary_by_work_type.png\")\n",
        "fig2.write_image(\"chart2_skills_vs_salary.png\")\n",
        "\n",
        "print(\"fig1 and fig2 have been saved as PNG files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### code block for skill_gap_analysis.qmd: \n",
        "#### Team-based Skill Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create list of relevant analytics skills and rate each member from 1-5\n",
        "import pandas as pd\n",
        "\n",
        "skills_data = {\n",
        "    \"Name\": [\"Angelina\", \"Devin\", \"Leo\"],\n",
        "    \"Python\": [3, 1, 3],\n",
        "    \"SQL\": [3, 3, 3],\n",
        "    \"Power BI\": [5, 4, 4],\n",
        "    \"Tableau\": [4, 3, 2],\n",
        "    \"Excel\": [5, 5, 4],\n",
        "    \"Machine Learning\": [2, 1, 1],\n",
        "    \"NLP\": [2, 1, 1],\n",
        "    \"Cloud Computing\": [1, 2, 1],\n",
        "    \"AWS\": [1, 1, 1]\n",
        "}\n",
        "\n",
        "# Convert to dataframe \n",
        "df_skills = pd.DataFrame(skills_data)\n",
        "df_skills.set_index(\"Name\", inplace=True)\n",
        "df_skills\n",
        "\n",
        "# Plot df as a heatmap to visualize skill distribution\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df_skills, annot=True, cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Team Skill Levels Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compare team skills to industry requirements\n",
        "#### NLP Processing Code Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Extract most in-demand skills from JD \n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from pathlib import Path\n",
        "import nltk\n",
        "\n",
        "nltk.data.path.append(str(Path.home() / \"nltk_data\"))\n",
        "\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "# Pull description from job postings and convert into strings\n",
        "job_descriptions = df[\"BODY\"].dropna().astype(str).tolist()\n",
        "\n",
        "## NLP processing\n",
        "# Combine all JD strings into one string and convert all to lowercase \n",
        "print(\"Combining job descriptions...\")\n",
        "all_text = \" \".join(job_descriptions).lower()\n",
        "\n",
        "# Extract only alphabetical and excludes punctuation, numeric values, symbols (Tokenizing)\n",
        "print(\"Running regex to extract words...\")\n",
        "words = re.findall(r'\\b[a-zA]+\\b', all_text)\n",
        "\n",
        "# Filter to remove common stopwords \n",
        "print(\"Filtering out stopwords...\")\n",
        "words_filtered = [word for word in words if word not in stopwords.words(\"english\")]\n",
        "\n",
        "# Count the frequency of each word\n",
        "print(\"Counting word frequencies...\")\n",
        "words_count = Counter(words_filtered)\n",
        "\n",
        "# Define a list of skills: \n",
        "skills_list = {\"python\", \"sql\", \"aws\", \"docker\", \"tableau\", \"excel\", \"pandas\", \"numpy\", \"power\", \"spark\", \"machine\", \"learning\", \"nlp\", \"cloud\", \"computing\"}\n",
        "\n",
        "# Extract the predefined skills that actually appear in the job postings text blob; \n",
        "skills_filtered = {\n",
        "  skill: words_count[skill]\n",
        "  for skill in skills_list\n",
        "  if skill in words_count\n",
        "}\n",
        "\n",
        "print(\"Top data analytics skills from job description\")\n",
        "for skill, count in skills_filtered.items():\n",
        "  print(f\"{skill}:{count}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (AD688 venv)",
      "language": "python",
      "name": "ad688-venv",
      "path": "/Users/leoliu/Library/Jupyter/kernels/ad688-venv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
