{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Project Working File\"\n",
        "execute:\n",
        "  kernel: ad688-venv\n",
        "bibliography: references.bib\n",
        "csl: csl/econometrica.csl\n",
        "format: \n",
        "  html:\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "    df-print: paged\n",
        "---\n",
        "\n",
        "## This file contains the code blocks for data cleaning, EDAs, skill gap analysis, NLP processing, etc. as a working file\n",
        "## Each file that contributes to the overall quarto website will contain the text and visual outputs only. \n",
        "\n",
        "\n",
        "### Code block for data_cleaning.qmd: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load lightcast_job_postings.csv \n",
        "df = pd.read_csv(\"data/lightcast_job_postings.csv\")\n",
        "\n",
        "# Show the first 5 rows \n",
        "print(df.head(5).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop columns\n",
        "columns_to_drop = [\n",
        "    # Meta/tracking\n",
        "    \"ID\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"DUPLICATES\", \"URL\",\n",
        "    \"ACTIVE_URLS\", \"ACTIVE_SOURCES_INFO\", \"SOURCE_TYPES\", \"SOURCES\",\n",
        "\n",
        "    # Duplicated location info\n",
        "    \"LOCATION\", \"CITY\", \"STATE\", \"COUNTY\", \"COUNTY_NAME\",\n",
        "    \"COUNTY_OUTGOING\", \"COUNTY_NAME_OUTGOING\", \"COUNTY_INCOMING\", \"COUNTY_NAME_INCOMING\",\n",
        "    \"MSA\", \"MSA_OUTGOING\", \"MSA_NAME_OUTGOING\", \"MSA_INCOMING\", \"MSA_NAME_INCOMING\",\n",
        "\n",
        "    # Raw/duplicate title & body\n",
        "    \"TITLE_RAW\", \"TITLE_NAME\",\n",
        "\n",
        "    # Duplicated employment info\n",
        "    \"EMPLOYMENT_TYPE\", \"EMPLOYMENT_TYPE_NAME\",\n",
        "\n",
        "    # Education code columns\n",
        "    \"EDUCATION_LEVELS\", \"EDUCATION_LEVELS_NAME\", \"MIN_EDULEVELS\", \"MAX_EDULEVELS\",\n",
        "\n",
        "    # Redundant NAICS/SOC versions\n",
        "    \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\", \"NAICS4\", \"NAICS4_NAME\",\n",
        "    \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\", \"NAICS6_NAME\",\n",
        "    \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_4\", \"SOC_4_NAME\",\n",
        "    \"SOC_5\",  # keep SOC_5_NAME, drop code\n",
        "    \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\",\n",
        "    \"SOC_2021_4\", \"SOC_2021_4_NAME\", \"SOC_2021_5\", \"SOC_2021_5_NAME\",\n",
        "\n",
        "    # LOT/V6 occupation hierarchy (keep only 1 specialized name field)\n",
        "    \"LOT_CAREER_AREA\", \"LOT_CAREER_AREA_NAME\", \"LOT_OCCUPATION\", \"LOT_OCCUPATION_NAME\",\n",
        "    \"LOT_OCCUPATION_GROUP\", \"LOT_OCCUPATION_GROUP_NAME\",\n",
        "    \"LOT_V6_SPECIALIZED_OCCUPATION\", \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\",\n",
        "    \"LOT_V6_OCCUPATION\", \"LOT_V6_OCCUPATION_NAME\",\n",
        "    \"LOT_V6_OCCUPATION_GROUP\", \"LOT_V6_OCCUPATION_GROUP_NAME\",\n",
        "    \"LOT_V6_CAREER_AREA\", \"LOT_V6_CAREER_AREA_NAME\",\n",
        "\n",
        "    # ONET & CIP codes (unless you're doing deep labor mapping)\n",
        "    \"ONET\", \"ONET_NAME\", \"ONET_2019\", \"ONET_2019_NAME\",\n",
        "    \"CIP2\", \"CIP2_NAME\", \"CIP4\", \"CIP4_NAME\", \"CIP6\", \"CIP6_NAME\",\n",
        "\n",
        "    # Sectors\n",
        "    \"LIGHTCAST_SECTORS\", \"LIGHTCAST_SECTORS_NAME\",\n",
        "\n",
        "    # NAICS 2022 lower-level codes\n",
        "    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n",
        "    \"NAICS_2022_4\", \"NAICS_2022_4_NAME\", \"NAICS_2022_5\", \"NAICS_2022_5_NAME\",\n",
        "    \"NAICS_2022_6\",  # drop code, keep name\n",
        "]\n",
        "\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Identify columns that have a significant amount of missing values and sort df by the percentage of missing values\n",
        "missing_percent = df.isnull().mean().sort_values(ascending=False)*100\n",
        "df_sorted = df[missing_percent.index]\n",
        "\n",
        "# Visualize missing data using missingno bar chart \n",
        "plt.figure(figsize=(12, 6))\n",
        "msno.bar(df_sorted)\n",
        "plt.title(\"Non-null Data Bar Chart\")\n",
        "plt.tight_layout()\n",
        "out_path = \"figures/non-null_data.png\"\n",
        "plt.savefig(out_path, dpi=150)\n",
        "plt.show()\n",
        "\n",
        "missing_values_pct = (missing_percent.reset_index().rename(columns={\"index\": \"Column\", 0: \"Missing %\"}))\n",
        "print(missing_values_pct.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop columns with >50% missing values\n",
        "cols_to_drop_missing = [\n",
        "    \"MAX_YEARS_EXPERIENCE\",\n",
        "    \"MAX_EDULEVELS_NAME\",\n",
        "    \"SALARY_FROM\",\n",
        "    \"SALARY_TO\",\n",
        "    \"ORIGINAL_PAY_PERIOD\",\n",
        "    \"MODELED_DURATION\",\n",
        "    \"MODELED_EXPIRED\",\n",
        "    \"EXPIRED\"\n",
        "]\n",
        "df.drop(columns=cols_to_drop_missing, inplace=True)\n",
        "\n",
        "# Fill categorical columns with \"Unknown\"\n",
        "fill_col_unk = [\n",
        "    # Company info\n",
        "    \"COMPANY_NAME\", \"COMPANY_IS_STAFFING\",\n",
        "    \n",
        "    # Job titles\n",
        "    \"TITLE\", \"TITLE_CLEAN\",\n",
        "    \n",
        "    # Occupation/industry (kept name fields)\n",
        "    \"SOC_5_NAME\", \"LOT_SPECIALIZED_OCCUPATION_NAME\", \"NAICS_2022_6_NAME\",\n",
        "    \n",
        "    # Remote type\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    \n",
        "    # Education level (names, not codes)\n",
        "    \"MIN_EDULEVELS_NAME\", \n",
        "    \n",
        "    # Location info\n",
        "    \"STATE_NAME\", \"CITY_NAME\", \"MSA_NAME\",\n",
        "    \n",
        "    # Skills/certifications (optional â€” only if you plan to analyze skills)\n",
        "    \"SKILLS_NAME\", \"SPECIALIZED_SKILLS_NAME\", \"COMMON_SKILLS_NAME\", \"CERTIFICATIONS_NAME\"\n",
        "]\n",
        "\n",
        "# Loop through and fill missing values\n",
        "for col in fill_col_unk:\n",
        "    df[col] = df[col].fillna(\"Unknown\")\n",
        "\n",
        "# Create a cleaned version for SALARY with median imputation\n",
        "df[\"SALARY_CLEANED\"] = df[\"SALARY\"].copy()\n",
        "median_salary = df[\"SALARY\"].median()\n",
        "df[\"SALARY_CLEANED\"] = df[\"SALARY_CLEANED\"].fillna(median_salary)\n",
        "\n",
        "# Drop columns with >50% missing values\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove duplicate\n",
        "df=df.drop_duplicates(subset=[\"TITLE_CLEAN\", \"COMPANY_NAME\", \"POSTED\", \"REMOTE_TYPE_NAME\", \"SKILLS_NAME\"], keep=\"first\")\n",
        "\n",
        "# Preview new df\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code block for eda.qmd: \n",
        "#### 5.1.1 Salary by Remote Work Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1.1 Visual - Compensation\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "values_to_exclude = ['Unknown', '[None]']\n",
        "df_filtered = df[~df['REMOTE_TYPE_NAME'].isin(values_to_exclude)]\n",
        "\n",
        "fig1 = px.box(\n",
        "    df_filtered,\n",
        "    x=\"REMOTE_TYPE_NAME\",\n",
        "    y=\"SALARY\",\n",
        "    title=\"Salary Distribution by Work Arrangement\",\n",
        "    labels={\"REMOTE_TYPE_NAME\": \"Work Arrangement\", \"SALARY\": \"Annual Salary ($)\"}\n",
        ")\n",
        "fig1.show()\n",
        "fig1.write_image(\"figures/salary_by_work_arrangement.png\", scale=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.1.2 Top Skills vs. Average Salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1.2 Visual - Skills vs. Salary\n",
        "import plotly.express as px\n",
        "import ast\n",
        "\n",
        "# This function safely converts the string of a list into an actual list\n",
        "def parse_skills(skill_list_str):\n",
        "    try:\n",
        "        return ast.literal_eval(skill_list_str)\n",
        "    except (ValueError, SyntaxError):\n",
        "        return []\n",
        "\n",
        "# Create a new column with the cleaned lists of skills\n",
        "df['SKILLS_LIST'] = df['SKILLS_NAME'].apply(parse_skills)\n",
        "\n",
        "# Create a new DataFrame where each skill gets its own row\n",
        "df_skills_exploded = df.explode('SKILLS_LIST')\n",
        "\n",
        "# --- Now, create the chart using the cleaned data ---\n",
        "top_10_skills_by_count = df_skills_exploded['SKILLS_LIST'].value_counts().nlargest(10).index\n",
        "df_top_skills = df_skills_exploded[df_skills_exploded['SKILLS_LIST'].isin(top_10_skills_by_count)]\n",
        "\n",
        "avg_salary_for_top_skills = df_top_skills.groupby('SKILLS_LIST')['SALARY'].mean().reset_index()\n",
        "\n",
        "fig2 = px.bar(\n",
        "    avg_salary_for_top_skills,\n",
        "    x='SKILLS_LIST',\n",
        "    y=\"SALARY\",\n",
        "    title=\"Average Salary for Top 10 Skills\",\n",
        "    labels={'SKILLS_LIST': \"Skill\", \"SALARY\": \"Average Annual Salary ($)\"}\n",
        ")\n",
        "fig2.show()\n",
        "fig2.write_image(\"figures/topskills_salary.png\", scale=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.1.3 Salary Distribution by Top Industries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Query Setup\n",
        "# Convert the POSTED date from string to date format\n",
        "df[\"POSTED\"] = pd.to_datetime(df[\"POSTED\"], errors=\"coerce\")\n",
        "\n",
        "# Filter for job postings from 2024, specifically looking at Salary and Industry. Exclude unknowns, nulls, and zeros. Exclude 'Unclassified Industry' \n",
        "df_jp_2024 = df[\n",
        "  (df[\"POSTED\"].dt.year==2024) & \n",
        "  (df[\"SALARY\"] > 0) & \n",
        "  (df[\"SALARY\"].notnull()) &\n",
        "  (df[\"NAICS_2022_6_NAME\"]!= \"Unknown\") &\n",
        "  (df[\"NAICS_2022_6_NAME\"]!= \"Unclassified Industry\")\n",
        "]\n",
        "\n",
        "## Further filter to exclude industries that have an insignificant number of job postings\n",
        "# count the number of rows per industry  \n",
        "industry_jp_count = df_jp_2024[\"NAICS_2022_6_NAME\"].value_counts()\n",
        "\n",
        "# summarize the distribution of job counts per industry\n",
        "industry_jp_count.describe()\n",
        "\n",
        "# Set minimum threshold at 100 job postings to ensure statistical significance\n",
        "top_jp_industries = industry_jp_count[industry_jp_count > 100].index\n",
        "\n",
        "# Update df to only show top job posting industries\n",
        "df_jp_2024 = df_jp_2024[df_jp_2024[\"NAICS_2022_6_NAME\"].isin(top_jp_industries)]\n",
        "\n",
        "## Plot: Analyze Median Salary by Industry (Seaborn)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# group by industry name and calculate median salary, sort by descending order\n",
        "top_industry_salary_order = df_jp_2024.groupby(\"NAICS_2022_6_NAME\")[\"SALARY\"].median().sort_values(ascending=False).head(12).index\n",
        "\n",
        "# create bar chart\n",
        "plt.figure(figsize = (14,8))\n",
        "sns.barplot(\n",
        "  orient='h',\n",
        "  data=df_jp_2024,\n",
        "  x=\"SALARY\",\n",
        "  y=\"NAICS_2022_6_NAME\",\n",
        "  order=top_industry_salary_order,\n",
        "  palette=\"Set2\",\n",
        "  width=0.6,\n",
        "  estimator=np.median,\n",
        "  errorbar=None\n",
        ")\n",
        "plt.title(\"Median Salary by Industry in 2024\", fontsize=14, weight=\"bold\")\n",
        "plt.xlabel(\"Median Salary ($)\", fontsize=12)\n",
        "plt.ylabel(\"Industry\", fontsize=12)\n",
        "plt.yticks(ha=\"right\", fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show\n",
        "out_path = \"figures/median_salary_by_industry.png\"\n",
        "plt.savefig(out_path, dpi=150)\n",
        "\n",
        "## Plot: Analyze Salary Distribution by Industry (Seaborn)\n",
        "# determine IQRs by industry:\n",
        "q25 = df_jp_2024.groupby(\"NAICS_2022_6_NAME\")[\"SALARY\"].quantile(0.25)\n",
        "q75 = df_jp_2024.groupby(\"NAICS_2022_6_NAME\")[\"SALARY\"].quantile(0.75)\n",
        "# sort by the middle 50% (Q3 - Q1) and name that as the new sorting order\n",
        "iqr = (q75 - q25).sort_values(ascending=False).head(12)\n",
        "iqr_order = iqr.index  \n",
        "\n",
        "# Create box plot\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.boxplot(\n",
        "  data=df_jp_2024,\n",
        "  y=\"NAICS_2022_6_NAME\",\n",
        "  x=\"SALARY\",\n",
        "  order=iqr_order,\n",
        "  palette=\"Set3\",\n",
        "  width=0.6\n",
        ")\n",
        "plt.title(\"Salary Distribution by Industry in 2024\", fontsize=14, weight=\"bold\")\n",
        "plt.ylabel(\"Industry\", fontsize=12)\n",
        "plt.xlabel(\"Salary ($)\", fontsize=12)\n",
        "plt.yticks(ha=\"right\", fontsize=9)\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show\n",
        "out_path = \"figures/salary_distribution_by_industry.png\"\n",
        "plt.savefig(out_path, dpi=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.1.4 AI vs. Non-AI Job Salary Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a lowercase version of the BODY column for keyword searching\n",
        "df[\"BODY\"] = df[\"BODY\"].astype(str).str.lower()\n",
        "\n",
        "# identify AI related keywords \n",
        "ai_keywords = [\n",
        "    \"machine learn\",  # matches 'machine learning', 'machine learner'\n",
        "    \"data scien\",     # matches 'data scientist', 'data science'\n",
        "    \"artificial intel\",  # matches 'artificial intelligence'\n",
        "    \"deep learn\",  \n",
        "    \"ml engineer\",            \n",
        "    \"data engineer\",\n",
        "    \"computer vision\", \n",
        "    \"natural language\", \n",
        "    \"nlp\",\n",
        "    \"big data\",\n",
        "    \"cloud data\"\n",
        "]\n",
        "\n",
        "# Create a regex pattern that matches any of the keywords, case-insensitive\n",
        "ai_pattern = re.compile(r\"|\".join([re.escape(k) for k in ai_keywords]), flags=re.IGNORECASE)\n",
        "\n",
        "# Assign a new column is_ai_job to label job postings with AI or Non-AI based on keyword presence in the BODY text\n",
        "df[\"is_ai_job\"] = df[\"BODY\"].apply(lambda text: \"AI\" if ai_pattern.search(text) else \"Non-AI\")\n",
        "\n",
        "# Filter out rows with null or zero salary and outliers \n",
        "df_filtered_1 = df[\n",
        "    (df[\"SALARY\"].notnull()) &\n",
        "    (df[\"SALARY\"] > 0)\n",
        "]\n",
        "q1 = df_filtered_1[\"SALARY\"].quantile(0.01)\n",
        "q99 = df_filtered_1[\"SALARY\"].quantile(0.99)\n",
        "df_filtered_1 = df_filtered_1[(df_filtered_1[\"SALARY\"] >= q1) & (df_filtered_1[\"SALARY\"] <= q99)]\n",
        "\n",
        "print(df_filtered_1[\"is_ai_job\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(\"Original:\", len(df))\n",
        "#print(\"Filtered:\", len(df_filtered_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_filtered_1, x=\"is_ai_job\", y=\"SALARY\")\n",
        "plt.title(\"Salary Distribution: AI vs. Non-AI Jobs\")\n",
        "plt.xlabel(\"Job Type\")\n",
        "plt.ylabel(\"Salary ($)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "out_path = \"figures/AI_v_nonAI_salary_boxplot.png\"\n",
        "plt.savefig(out_path, dpi=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(data=df_filtered_1, x=\"SALARY\", hue=\"is_ai_job\", common_norm=False)\n",
        "plt.title(\"Salary Density: AI vs. Non-AI Jobs\")\n",
        "plt.xlabel(\"Salary ($)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- Export All Charts -----\n",
        "import plotly.express as px\n",
        "import ast \n",
        "\n",
        "fig1.write_image(\"chart1_salary_by_work_type.png\")\n",
        "fig2.write_image(\"chart2_skills_vs_salary.png\")\n",
        "\n",
        "print(\"fig1 and fig2 have been saved as PNG files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### code block for skill_gap_analysis.qmd: \n",
        "#### Team-based Skill Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create list of relevant analytics skills and rate each member from 1-5\n",
        "import pandas as pd\n",
        "\n",
        "skills_data = {\n",
        "    \"Name\": [\"Angelina\", \"Devin\", \"Leo\"],\n",
        "    \"Python\": [3, 1, 3],\n",
        "    \"SQL\": [3, 3, 3],\n",
        "    \"Power BI\": [5, 4, 4],\n",
        "    \"Tableau\": [4, 3, 2],\n",
        "    \"Excel\": [5, 5, 4],\n",
        "    \"Machine Learning\": [2, 1, 1],\n",
        "    \"NLP\": [2, 1, 1],\n",
        "    \"Cloud Computing\": [1, 2, 1],\n",
        "    \"AWS\": [1, 1, 1]\n",
        "}\n",
        "\n",
        "# Convert to dataframe \n",
        "df_skills = pd.DataFrame(skills_data)\n",
        "df_skills.set_index(\"Name\", inplace=True)\n",
        "df_skills\n",
        "\n",
        "# Plot df as a heatmap to visualize skill distribution\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df_skills, annot=True, cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Team Skill Levels Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compare team skills to industry requirements\n",
        "#### NLP Processing Code Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Extract most in-demand skills from JD \n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from pathlib import Path\n",
        "import nltk\n",
        "\n",
        "nltk.data.path.append(str(Path.home() / \"nltk_data\"))\n",
        "\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "# Pull description from job postings and convert into strings\n",
        "job_descriptions = df[\"BODY\"].dropna().astype(str).tolist()\n",
        "\n",
        "## NLP processing\n",
        "# Combine all JD strings into one string and convert all to lowercase \n",
        "print(\"Combining job descriptions...\")\n",
        "all_text = \" \".join(job_descriptions).lower()\n",
        "\n",
        "# Extract only alphabetical and excludes punctuation, numeric values, symbols (Tokenizing)\n",
        "print(\"Running regex to extract words...\")\n",
        "words = re.findall(r'\\b[a-zA]+\\b', all_text)\n",
        "\n",
        "# Filter to remove common stopwords \n",
        "print(\"Filtering out stopwords...\")\n",
        "words_filtered = [word for word in words if word not in stopwords.words(\"english\")]\n",
        "\n",
        "# Count the frequency of each word\n",
        "print(\"Counting word frequencies...\")\n",
        "words_count = Counter(words_filtered)\n",
        "\n",
        "# Define a list of skills: \n",
        "skills_list = {\"python\", \"sql\", \"aws\", \"docker\", \"tableau\", \"excel\", \"pandas\", \"numpy\", \"power\", \"spark\", \"machine\", \"learning\", \"nlp\", \"cloud\", \"computing\"}\n",
        "\n",
        "# Extract the predefined skills that actually appear in the job postings text blob; \n",
        "skills_filtered = {\n",
        "  skill: words_count[skill]\n",
        "  for skill in skills_list\n",
        "  if skill in words_count\n",
        "}\n",
        "\n",
        "print(\"Top data analytics skills from job description\")\n",
        "for skill, count in skills_filtered.items():\n",
        "  print(f\"{skill}:{count}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (AD688 venv)",
      "language": "python",
      "name": "ad688-venv",
      "path": "/Users/leoliu/Library/Jupyter/kernels/ad688-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
